{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41dd20eb",
   "metadata": {},
   "source": [
    "# Variational Quantum Classifier for Heart Disease Prediction\n",
    "\n",
    "This notebook is our team's submission for the **final capstone project** in the [**Road to Quantum Practitioner**](https://quantum-computing.ibm.com/lab/courses) course organized by **IBM Quantum**.\n",
    "It implements a **Variational Quantum Classifier (VQC)** to predict heart disease using the UCI Heart Disease dataset.\n",
    "\n",
    "The project follows a structured pipeline, including:\n",
    "\n",
    "* **Prerequisites Setup:** Installing and importing all required libraries and tools for Qiskit and quantum computing.\n",
    "* **Defined Constants:** Declaring all configurable constants for qubit count, optimization method, number of shots, data paths etc.\n",
    "* **Data Preparation:** Loading and preprocessing the heart disease dataset, including normalization of input features for quantum encoding.\n",
    "* **Quantum Circuit Preparation:** Designing the quantum feature map, constructing the variational ansatz, and composing the full quantum circuit.\n",
    "* **Utility Functions:** Implementing helper functions for parameter management, label parsing, and probability extraction from measurement outcomes.\n",
    "* **Classification and Cost Evaluation:** Defining the classifier and cost functions, including binary cross-entropy (BCE) for training feedback.\n",
    "* **Execution and Optimization:** Selecting a simulator or real backend, transpiling the circuits, and optimizing parameters using COBYLA or CMA-ES.\n",
    "* **Result Visualization:** Plotting the evolution of the cost function and testing the trained quantum model on unseen data.\n",
    "\n",
    "It adheres to modern **Qiskit** practices and is designed for clarity, reproducibility, and experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e31a0",
   "metadata": {},
   "source": [
    "## Team members\n",
    "\n",
    "This project was developed by the following participants of the **IBM Quantum Road to Practitioner** course:\n",
    "\n",
    "- **Lung Rodica Ioana** - UBB, CSC\n",
    "- **Mahu Gheorghe** - UMF Iași, CTT\n",
    "- **Mihoc Tudor-Dan** - UBB, CSC\n",
    "- **Șofariu Adrian** - UBB\n",
    "- **Șoptelea Sebastian** - UBB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d8cd8b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b87631d",
   "metadata": {},
   "source": [
    "## 📚 Table of Contents\n",
    "\n",
    "<details>\n",
    "<summary><strong>Prerequisites</strong></summary>\n",
    "\n",
    "* [Installing Required Packages](#installing-required-packages)\n",
    "* [Importing the Packages](#importing-the-packages)\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>Defined Constants</strong></summary>\n",
    "\n",
    "* [Defined Constants](#constants)\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>Data Preparation</strong></summary>\n",
    "\n",
    "* [Data Normalization for Quantum Encoding](#data-normalization-for-quantum-encoding)\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>Quantum Circuit Preparation</strong></summary>\n",
    "\n",
    "* [Quantum Feature Map Initialization](#quantum-feature-map-initialization)\n",
    "* [Ansatz Circuit Construction](#ansatz-circuit-construction)\n",
    "* [Quantum Circuit Composition](#quantum-circuit-composition)\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>Quantum Circuit Utility Functions</strong></summary>\n",
    "\n",
    "* [Parameter Dictionary Creation for Quantum Circuit](#parameter-dictionary-creation-for-quantum-circuit)\n",
    "* [Label Assignment Based on Bit String Parity](#label-assignment-based-on-bit-string-parity)\n",
    "* [Probability Calculation from Quantum Measurement Counts](#probability-calculation-from-quantum-measurement-counts)\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>Quantum Classification and Cost Functions</strong></summary>\n",
    "\n",
    "* [Quantum Circuit Classification](#quantum-circuit-classification)\n",
    "* [Cost Functions](#cost-functions)\n",
    "\n",
    "  * [BCE Cost](#binary-cross-entropy-cost)\n",
    "  * [Cost Function for Quantum Circuit Training](#cost-function-for-quantum-circuit-training)\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>Quantum Execution and Optimization</strong></summary>\n",
    "\n",
    "* [Backend Setup and Transpilation](#backend-setup-and-transpilation)\n",
    "* [Quantum Circuit Parameter Optimization](#quantum-circuit-parameter-optimization)\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary><strong>Result Visualization</strong></summary>\n",
    "\n",
    "* [Cost Function Evolution](#cost-function-evolution)\n",
    "* [Quantum Classifier Testing](#quantum-classifier-testing)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20c9bf5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637909b8",
   "metadata": {},
   "source": [
    "## **Prerequisites**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fae479b",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### **Installing Required Packages**\n",
    "\n",
    "To ensure all necessary libraries are available for this notebook, we use `pip` to install the required Python packages. \n",
    "\n",
    "This approach guarantees that the environment contains the latest versions of essential tools for quantum computing, data processing, and visualization.  \n",
    "The `%pip` magic command is used within Jupyter notebooks to install packages directly from a notebook cell, making the setup process straightforward and reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9edf4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantum Computing Framework\n",
    "%pip install qiskit\n",
    "%pip install qiskit-aer\n",
    "%pip install qiskit-ibm-runtime\n",
    "%pip install qiskit[visualization]\n",
    "\n",
    "# Data Science and Machine Learning\n",
    "%pip install scikit-learn\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "\n",
    "# Visualization and Plotting\n",
    "%pip install matplotlib\n",
    "%pip install matplotlib_inline\n",
    "\n",
    "# Optimization\n",
    "%pip install cma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caa78d3",
   "metadata": {},
   "source": [
    "### **Importing the Packages**\n",
    "\n",
    "Following our installation of the packages, we need to import them to access the required methods and classes in our code. The imports are organized following Python conventions:\n",
    "\n",
    "- **Standard libraries**: Core Python packages for data manipulation and visualization\n",
    "- **Third-party and Scikit-learn libraries**: Specialized tools for optimization and machine learning\n",
    "- **Qiskit libraries**: Quantum computing framework components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f8791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from datetime import datetime\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "# Third-party optimization libraries\n",
    "import cma\n",
    "from scipy.optimize import minimize\n",
    "import scipy.stats as st\n",
    "\n",
    "# Scikit-learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# Qiskit imports\n",
    "import qiskit\n",
    "from qiskit import generate_preset_pass_manager\n",
    "from qiskit.circuit.library import real_amplitudes, zz_feature_map\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, SamplerV2 as Sampler, Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca46aaa8",
   "metadata": {},
   "source": [
    "A small check to ensure everything is okay:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dba205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Qiskit is installed and print the version\n",
    "if 'qiskit' in globals():\n",
    "    print(f\"Qiskit version: {qiskit.__version__}\") # The version of Qiskit which we are currently using is 2.1.1. In the future, methods and classes may change\n",
    "                                                   # or become deprecated, so it may be necessary to update the code accordingly.\n",
    "else:\n",
    "    print(\"Qiskit is not installed or not available in the current environment. Re-run the `Installing Required Packages` cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fcd01d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800f3c65",
   "metadata": {},
   "source": [
    "## **Constants**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e44a6e",
   "metadata": {},
   "source": [
    "The script uses a set of global constants to control quantum circuit setup, data processing, optimization, and backend selection. These values can be easily modified to experiment with different settings (e.g., changing optimizers, adjusting iteration counts, or switching between real and simulated quantum hardware).\n",
    "\n",
    "Feel free to tweak them to explore the model's behavior under different conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf2a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Quantum Circuit Parameters ====\n",
    "QUBIT_COUNT = 4            # Number of qubits (i.e., input features)\n",
    "SHOT_COUNT = 1024          # Number of shots (circuit executions per sample)\n",
    "CLASS_LABELS = ['healthy', 'diseased']  # Binary class labels used for classification\n",
    "\n",
    "# ==== Dataset and Preprocessing ====\n",
    "HEART_DATA_PATH = 'heartdata.csv'  # Path to the heart disease dataset CSV\n",
    "TEST_SIZE = 0.3                    # Test split size (30% for evaluation)\n",
    "\n",
    "# ==== Reproducibility ====\n",
    "RANDOM_STATE = 42            # Seed for consistent behavior across runs\n",
    "LOAD_FROM_CHECKPOINT = True  # If True, load parameters and cost list from checkpoint files if they exist\n",
    "\n",
    "# ==== Optimization ====\n",
    "COBYLA_ITER_COUNT = 70     # Iteration limit for the COBYLA optimizer\n",
    "CMA_ITER_COUNT = 150       # Iteration limit for the CMA-ES optimizer. !!! May go over this limit due to the check being made at the end of each iteration\n",
    "USE_CMA = False            # Flag to choose CMA-ES (True) or COBYLA (False)\n",
    "CMA_POPSIZE = 20           # Population size for CMA-ES (default is 4 + 3 * log(n) where n is the number of parameters)\n",
    "PRINT_COST = True          # Print cost value at each step if True\n",
    "\n",
    "# ==== Testing ====\n",
    "TEST_ITER_COUNT = 30       # Number of test repetitions to average final accuracy\n",
    "\n",
    "# ==== Backend Selection ====\n",
    "USE_REAL_BACKEND = False   # If True, use real IBM Quantum backend; else use simulator\n",
    "REGION = 'us-east'         # Region for Qiskit Runtime service: 'eu-de' or 'us-east'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e57c9d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c748ba0",
   "metadata": {},
   "source": [
    "## **Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450656ec",
   "metadata": {},
   "source": [
    "### **Data Normalization for Quantum Encoding**\n",
    "\n",
    "This function loads and normalizes heart disease dataset features and labels for use in quantum machine learning applications.\n",
    "\n",
    "#### **Source**\n",
    "\n",
    "According to the paper:  \n",
    "**[Explainable Artificial Intelligence Framework for Multimodal Data Analysis](https://www.nature.com/articles/s41598-022-24633-4)**,  \n",
    "the most clinically relevant traits to diagnose cardiac disorders include:  \n",
    "`cp`, `ca`, `thal`, `age`, `thalach`, `chol`, `oldpeak`, and `sex`.\n",
    "\n",
    "Of these, the most important are:\n",
    "- `ca` (number of major vessels colored by fluoroscopy)  \n",
    "- `cp` (chest pain type)  \n",
    "- `thal` (thalassemia)  \n",
    "- `oldpeak` (ST depression induced by exercise)\n",
    "\n",
    "However, over half of the dataset contains missing values for `ca` and `thal`.  \n",
    "To preserve as much usable data as possible, we dropped these and selected features from those with minimal nulls.\n",
    "\n",
    "#### **Feature Selection Rationale**\n",
    "\n",
    "From the remaining mostly complete columns, we selected:\n",
    "- `cp` (chest pain type)  \n",
    "- `oldpeak` (ST depression induced by exercise)  \n",
    "- `sex` (gender)  \n",
    "- `exang` (exercise-induced angina)\n",
    "\n",
    "This decision was reinforced by multiple trials and confirmed during exploratory data analysis in [this notebook](https://github.com/rodneyosodo/variational-quantum-classifier-on-heartattack/blob/main/Src/Notebooks/01dataExploration.ipynb),\n",
    "where these features consistently ranked among the most defining predictors of heart disease.\n",
    "\n",
    "#### **Final Selected Features**\n",
    "\n",
    "- `cp`, `oldpeak`, `sex`, `exang`  \n",
    "These were chosen to match a 4-qubit quantum model.\n",
    "\n",
    "#### **Output**\n",
    "\n",
    "Returns the normalized training and test features and labels as a tuple.  \n",
    "Features are scaled to `(0, π)` to enable valid angle encoding for quantum gates (e.g. `Ry`, `Rx`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64193d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data() -> tuple:\n",
    "    \"\"\"\n",
    "    Load and normalize heart disease dataset features and labels for quantum machine learning.\n",
    "\n",
    "    Selected 4 features — 'cp', 'oldpeak', 'sex', and 'exang' — are scaled to the range (0, π) \n",
    "    for angle encoding in quantum circuits.\n",
    "\n",
    "    These features were chosen based on feature importance, data completeness, and validation \n",
    "    through exploratory analysis.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Normalized (X_train, X_test) features and (Y_train, Y_test) labels.\n",
    "    \"\"\"\n",
    "    # Load dataset and shuffle to randomize sample order\n",
    "    df = pd.read_csv(HEART_DATA_PATH)\n",
    "    df = shuffle(df, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Select top 4 features for 4-qubit quantum encoding\n",
    "    X = df[['cp', 'oldpeak', 'sex', 'exang']].values\n",
    "    Y = df['num'].values\n",
    "\n",
    "    # Split before scaling to avoid data leakage\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "\n",
    "    # Normalize inputs between 0 and π for angle encoding\n",
    "    # The range (0, np.pi) is chosen to ensure that the angles used in quantum circuits are within a valid range for angle encoding.\n",
    "    # This is important for quantum circuits that use angle encoding (e.g. Rx, Ry gates), as angles outside this range may\n",
    "    # lead to incorrect results or inefficiencies in the quantum computation.\n",
    "    scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c3262e",
   "metadata": {},
   "source": [
    "Obtaining the actual train and test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae723974",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = normalize_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518253ac",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c23334",
   "metadata": {},
   "source": [
    "## **Quantum Circuit Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d88864b",
   "metadata": {},
   "source": [
    "### **Quantum Feature Map Initialization**\n",
    "\n",
    "Initializes a ZZFeatureMap circuit to encode classical input features into a quantum state for machine learning.\n",
    "\n",
    "#### **Configuration**\n",
    "\n",
    "* **Initial state**: All qubits set to $|0\\rangle$\n",
    "* **Feature map**: ZZFeatureMap with linear entanglement\n",
    "* **Repetitions**: 2 layers for increased expressiveness\n",
    "* **Qubit count**: Equals number of input features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d02e533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the initial quantum state (all qubits in |0⟩ state)\n",
    "state = Statevector.from_label('0' * QUBIT_COUNT)\n",
    "\n",
    "# Create the ZZFeatureMap for encoding classical data into quantum states\n",
    "feature_map = zz_feature_map(\n",
    "    feature_dimension=QUBIT_COUNT, # Number of features/qubits\n",
    "    reps=2,                        # Number of repetitions of the feature map circuit\n",
    "    entanglement='linear'          # How qubits are entangled (linear = nearest neighbors)\n",
    ")\n",
    "\n",
    "# Visualize the feature map circuit\n",
    "feature_map.draw(output='mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b1378d",
   "metadata": {},
   "source": [
    "### **Ansatz Circuit Construction**\n",
    "\n",
    "Defines the parameterized quantum circuit (ansatz) used for learning in a variational quantum algorithm.\n",
    "\n",
    "#### **Configuration**\n",
    "\n",
    "* **Circuit type**: RealAmplitudes\n",
    "* **Qubit count**: Matches the feature dimension\n",
    "* **Entanglement**: Linear pattern\n",
    "* **Repetitions**: 1 layer of parameterized gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9c13ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the ansatz circuit used for parameterized learning\n",
    "# This circuit will be optimized during training\n",
    "ansatz = real_amplitudes(\n",
    "    num_qubits=QUBIT_COUNT,  # Number of qubits = number of features\n",
    "    reps=1,                  # One repetition layer of rotations + entanglement\n",
    "    entanglement='linear'    # Linear entanglement between qubits\n",
    ")\n",
    "\n",
    "# Visualize the decomposed circuit\n",
    "ansatz.decompose().draw(output='mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3aaa8",
   "metadata": {},
   "source": [
    "### **Quantum Circuit Composition**\n",
    "\n",
    "Combines the data-encoding feature map with the parameterized ansatz circuit.\n",
    "\n",
    "#### **Configuration**\n",
    "\n",
    "* **Feature Map**: Encodes classical features into quantum states\n",
    "* **Ansatz**: Trainable circuit for learning patterns\n",
    "* **Output Circuit**: Used for quantum machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df64f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose the full quantum circuit by combining feature map and ansatz\n",
    "# The feature map encodes the input data; ansatz is the trainable part\n",
    "circuit = feature_map.compose(ansatz, inplace=False)\n",
    "\n",
    "# Visualize the decomposed circuit with multiple repetitions for clarity\n",
    "circuit.decompose(reps=8).draw(output='mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1bbdbb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885b8a0b",
   "metadata": {},
   "source": [
    "## **Quantum Circuit Utility Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04678a1b",
   "metadata": {},
   "source": [
    "### **Parameter Dictionary Creation for Quantum Circuit**\n",
    "\n",
    "This function creates a dictionary that maps parameters of both the feature map and ansatz circuits to their corresponding values.\n",
    "\n",
    "#### **Output**\n",
    "\n",
    "Returns a dictionary that associates each circuit parameter with its value, combining input features for the feature map and weights for the ansatz.  \n",
    "Used to bind values before running the quantum circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc1c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dict(params: list, x: list) -> dict:\n",
    "    \"\"\"\n",
    "    Create a dictionary of parameters for the feature map and ansatz.\n",
    "\n",
    "    Args:\n",
    "        params (list): List of parameters for the ansatz (trainable weights).\n",
    "        x (list): List of features for the feature map (input data).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary mapping circuit parameters to their corresponding values.\n",
    "    \"\"\"\n",
    "    parameters = {}\n",
    "    for i, p in enumerate(feature_map.parameters):\n",
    "        parameters[p] = x[i]  # Bind feature values to feature map parameters\n",
    "    for i, p in enumerate(ansatz.parameters):\n",
    "        parameters[p] = params[i]  # Bind trainable ansatz parameters\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81f2264",
   "metadata": {},
   "source": [
    "### **Label Assignment Based on Bit String Parity**\n",
    "\n",
    "This function assigns a class label by calculating the parity of the Hamming weight (number of 1s) in a given bit string.\n",
    "\n",
    "#### **Processing Details**\n",
    "\n",
    "- Computes the Hamming weight of the bit string.\n",
    "- Determines if the parity (sum of bits) is even or odd.\n",
    "- Returns the first class label if parity is even, otherwise the second class label.\n",
    "\n",
    "#### **Output**\n",
    "\n",
    "Returns a class label based on the parity, useful for interpreting quantum measurement outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3679c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_label(bit_string: str, class_labels: list) -> str:\n",
    "    \"\"\"\n",
    "    Assign a label based on the parity of the Hamming weight of the bit string.\n",
    "    Args:\n",
    "        bit_string (str): A string of bits representing the quantum state.\n",
    "        class_labels (list): A list of class labels, e.g., ['yes', 'no'].\n",
    "    Returns:\n",
    "        str: The assigned class label based on the parity of the Hamming weight.\n",
    "    \"\"\"\n",
    "    hamming_weight = sum([int(bit) for bit in list(bit_string)]) # Count the number of 1s in the bit string\n",
    "    is_odd_parity = hamming_weight & 1 # Check if the Hamming weight is odd (1) or even (0)\n",
    "    if is_odd_parity:\n",
    "        return class_labels[1] # Return the second class label for odd parity\n",
    "    else:\n",
    "        return class_labels[0] # Return the first class label for even parity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd90098",
   "metadata": {},
   "source": [
    "### **Probability Calculation from Quantum Measurement Counts**\n",
    "\n",
    "This function computes the probability of each class label based on measurement outcomes (bit string counts) from a quantum circuit.\n",
    "\n",
    "#### **Processing Details**\n",
    "\n",
    "* Takes the counts of measured bit strings from quantum circuit runs.\n",
    "* Uses the `assign_label` function to classify each bit string based on parity.\n",
    "* Aggregates probabilities by summing the relative frequencies of bit strings assigned to each class.\n",
    "\n",
    "#### **Output**\n",
    "\n",
    "Returns a dictionary mapping each class label to its probability, representing the likelihood of the quantum circuit outputting that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2814e65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_probabilities(counts: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate the probabilities of each class label based on the counts of bit strings.\n",
    "    Args:\n",
    "        counts (dict): A dictionary containing the counts of bit strings.\n",
    "    Returns:\n",
    "        dict: A dictionary with class labels as keys and their probabilities as values.\n",
    "    \"\"\"\n",
    "    shots = sum(counts.values()) # Total number of shots (measurements)\n",
    "    result = {CLASS_LABELS[0]: 0, CLASS_LABELS[1]: 0} # Initialize result dictionary with class labels\n",
    "    for key in counts:\n",
    "        label = assign_label(key, CLASS_LABELS) # Assign label based on parity of the bit string\n",
    "        result[label] += counts[key] / shots # Normalize counts to probabilities\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58451b3f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab83c0a",
   "metadata": {},
   "source": [
    "## **Quantum Classification and Cost Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8553ff3c",
   "metadata": {},
   "source": [
    "### **Quantum Circuit Classification**\n",
    "\n",
    "This function classifies multiple input feature vectors by running parameterized quantum circuits on a simulator or quantum backend.\n",
    "\n",
    "#### **Processing Details**\n",
    "\n",
    "* For each input feature vector:\n",
    "\n",
    "  * Binds feature data and ansatz parameters to the quantum circuit.\n",
    "  * Adds measurement operations to read out qubit states.\n",
    "  * Transpiles/prepares the circuit for execution.\n",
    "* Runs all circuits in batch on the quantum sampler.\n",
    "* Converts measurement results into class probabilities using parity-based labeling.\n",
    "\n",
    "#### **Output**\n",
    "\n",
    "Returns a list of dictionaries, each containing class labels and their associated probabilities for the corresponding input feature vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09513e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(x_list: list, params: list, sampler: any, pm: any) -> list:\n",
    "    \"\"\"\n",
    "    Classify a list of feature vectors using the quantum circuit.\n",
    "\n",
    "    Args:\n",
    "        x_list (list): A list of feature vectors to classify.\n",
    "        params (list): A list of parameters for the ansatz.\n",
    "        sampler: Quantum sampler backend to run the circuits. Either a simulator or a real quantum backend.\n",
    "        pm: Quantum processor manager or transpiler to prepare circuits.\n",
    "\n",
    "    Returns:\n",
    "        list of dict: Each dict contains class labels as keys and their probabilities as values.\n",
    "    \"\"\"\n",
    "    qc_list = []\n",
    "\n",
    "    for x in x_list:\n",
    "        # Bind input features and ansatz parameters to the circuit\n",
    "        classifier = circuit.assign_parameters(get_data_dict(params, x))\n",
    "        # Add measurement operations on all qubits\n",
    "        classifier.measure_all()\n",
    "\n",
    "        # Transpile or prepare the circuit for the backend\n",
    "        transpiled_circuit = pm.run(classifier)\n",
    "        qc_list.append(transpiled_circuit)\n",
    "\n",
    "    # Execute all circuits on the simulator or quantum backend\n",
    "    results = sampler.run(qc_list, shots=SHOT_COUNT).result()\n",
    "    probs = []\n",
    "\n",
    "    for qc in results:\n",
    "        # Extract counts of measurement outcomes\n",
    "        counts = qc.data.meas.get_counts()\n",
    "        # Convert counts to probabilities for each class label\n",
    "        prob = return_probabilities(counts)\n",
    "        probs.append(prob)\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2358081",
   "metadata": {},
   "source": [
    "### **Cost Functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8980b76c",
   "metadata": {},
   "source": [
    "#### **Binary Cross-Entropy Cost**\n",
    "\n",
    "This function calculates the Binary Cross-Entropy (BCE) loss for a predicted probability corresponding to the expected class label.\n",
    "\n",
    "##### **Output**\n",
    "\n",
    "Returns the BCE loss, a measure of how well the predicted probability matches the expected class (lower is better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aaade6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(probs: dict, expected_label: str) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Binary Cross-Entropy (BCE) cost function.\n",
    "\n",
    "    Args:\n",
    "        probs (dict): Predicted probabilities keyed by class labels (strings).\n",
    "        expected_label (str): The true class label.\n",
    "\n",
    "    Returns:\n",
    "        float: Binary Cross-Entropy loss value.\n",
    "    \"\"\"\n",
    "    eps = 1e-10  # Small value to avoid log(0) errors\n",
    "\n",
    "    # Get predicted probability for the expected label, clipped for numerical stability\n",
    "    p = probs.get(expected_label, 0.0)\n",
    "    p = np.clip(p, eps, 1 - eps)\n",
    "\n",
    "    # Compute BCE loss\n",
    "    return -np.log(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571ccf52",
   "metadata": {},
   "source": [
    "#### **Cost Function for Quantum Circuit Training**\n",
    "\n",
    "Calculates the average loss over the dataset by comparing predicted probabilities against expected labels using Binary Cross-Entropy.\n",
    "\n",
    "##### **Output**\n",
    "\n",
    "Returns the average cost (loss), which guides optimization of the quantum circuit parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f28c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(X: list, Y: list, params: list, cost_list: list, sampler: any, pm: any, max_iters: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the average cost over the dataset using given parameters.\n",
    "\n",
    "    Args:\n",
    "        X (list): Feature vectors to classify.\n",
    "        Y (list): Corresponding labels (0 or 1).\n",
    "        params (list): Parameters for the ansatz circuit.\n",
    "        cost_list (list): List to store the computed cost values.\n",
    "        sampler: Quantum sampler backend to run the circuits. Either a simulator or a real quantum backend.\n",
    "        pm: Quantum processor manager or transpiler to prepare circuits.\n",
    "\n",
    "    Returns:\n",
    "        float: Average cost over all samples.\n",
    "    \"\"\"\n",
    "    cost = 0\n",
    "    training_labels = []\n",
    "    training_samples = []\n",
    "\n",
    "    # Prepare samples and convert labels to string class labels\n",
    "    for sample in X:\n",
    "        training_samples.append(sample)\n",
    "    for label in Y:\n",
    "        if label == 0:\n",
    "            training_labels.append(CLASS_LABELS[0])\n",
    "        elif label == 1:\n",
    "            training_labels.append(CLASS_LABELS[1])\n",
    "\n",
    "    # Classify samples using the current parameters\n",
    "    probs = classify(training_samples, params, sampler, pm)\n",
    "\n",
    "    # Calculate binary cross-entropy cost for each sample and sum\n",
    "    for i, prob in enumerate(probs):\n",
    "        cost += binary_cross_entropy(prob, training_labels[i])\n",
    "\n",
    "    # Average cost over all samples\n",
    "    cost /= len(training_samples)\n",
    "\n",
    "    # Optionally print the cost, if enabled\n",
    "    if PRINT_COST:\n",
    "        step = len(cost_list) + 1\n",
    "        if not USE_CMA:\n",
    "            print(f\"[{step}/{max_iters}]: Current cost (BCE) = {cost:.6f}\")\n",
    "        else:\n",
    "            print(f\"[{step}]: Current cost (BCE) = {cost:.6f}\")\n",
    "\n",
    "    # Store cost value for tracking\n",
    "    cost_list.append(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134db617",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805d6bec",
   "metadata": {},
   "source": [
    "## **Quantum Execution and Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98cf15a",
   "metadata": {},
   "source": [
    "### **Backend Setup and Transpilation**\n",
    "\n",
    "This logic configures the quantum backend for circuit execution, either using a real QPU or a simulator, depending on the `USE_REAL_BACKEND` flag.\n",
    "\n",
    "#### **Processing Details**\n",
    "\n",
    "* If `USE_REAL_BACKEND` is enabled:\n",
    "\n",
    "  * Connects to the appropriate **IBM Quantum region** (`freeya` or `freeya-us`).\n",
    "  * Selects the **least busy** real quantum backend that is operational.\n",
    "  * Creates a `Session` with that backend for optimized scheduling.\n",
    "* Otherwise:\n",
    "\n",
    "  * Uses the **AerSimulator** to emulate a real QPU layout (specifically `ibm_aachen`, a Heron R2 device).\n",
    "  * This allows for transpilation and circuit testing that mirrors hardware constraints.\n",
    "\n",
    "#### **Transpilation and Analysis**\n",
    "\n",
    "* The `generate_preset_pass_manager()` function is used to optimize the quantum circuit.\n",
    "* The transpiled circuit is analyzed for **two-qubit gate depth**, which impacts execution cost and fidelity on real devices.\n",
    "* The final circuit is rendered using Matplotlib.\n",
    "\n",
    "#### **Output**\n",
    "\n",
    "* Prints the backend being used and the depth of two-qubit gates.\n",
    "* Displays a visual of the transpiled circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b18d850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up runtime service based on region\n",
    "service = QiskitRuntimeService(name=\"freeya\")\n",
    "\n",
    "if USE_REAL_BACKEND:\n",
    "    if REGION == 'us-east':\n",
    "        service = QiskitRuntimeService(name=\"freeya-us\") # In the case that we use a real backend, the region matters due to availability of backends.\n",
    "                                                         # When we use simulations, regions do not matter so we can use a default QPU e.g. ibm_aachen\n",
    "\n",
    "    # Get least busy real backend\n",
    "    backend = service.least_busy(min_num_qubits=5)\n",
    "    \n",
    "    session = Session(backend=backend, max_time=9000)\n",
    "    sampler = Sampler(mode=session)\n",
    "\n",
    "    print(f\"Using real backend: {backend.name}\")\n",
    "else:\n",
    "    # Use AerSimulator mimicking a real backend layout (Heron r2)\n",
    "    real_backend = service.backend(\"ibm_aachen\")  # Only used as template\n",
    "    backend = AerSimulator().from_backend(real_backend)\n",
    "\n",
    "    sampler = Sampler(mode=backend)\n",
    "    print(\"Using AerSimulator based on ibm_aachen\")\n",
    "\n",
    "# Prepare pass manager\n",
    "pm = generate_preset_pass_manager(backend=backend, optimization_level=3)\n",
    "\n",
    "# Transpile and analyze the circuit\n",
    "transpiled_circuit = pm.run(circuit)\n",
    "depth_2q = transpiled_circuit.depth(lambda x: len(x.qubits) == 2)\n",
    "print(f\"Depth of two-qubit gates: {depth_2q}\")\n",
    "\n",
    "# Draw the circuit\n",
    "transpiled_circuit.draw(output=\"mpl\", idle_wires=False, fold=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c32225",
   "metadata": {},
   "source": [
    "### **Quantum Circuit Parameter Optimization**\n",
    "\n",
    "This section optimizes the variational parameters of the quantum circuit using either **CMA-ES** or **COBYLA**, based on the `USE_CMA` flag.\n",
    "\n",
    "#### **Optimizer Options**\n",
    "\n",
    "* **CMA-ES** (Covariance Matrix Adaptation Evolution Strategy):\n",
    "\n",
    "  * Evolutionary algorithm suitable for noisy or non-convex problems\n",
    "  * Handles parameter noise using `cma.NoiseHandler`\n",
    "  * Controlled by `CMA_ITER_COUNT`\n",
    "\n",
    "* **COBYLA** (Constrained Optimization BY Linear Approximations):\n",
    "\n",
    "  * Gradient-free optimizer based on linear approximations\n",
    "  * Ideal for small parameter spaces and quick iterations\n",
    "  * Controlled by `COBYLA_ITER_COUNT`\n",
    "\n",
    "#### **Processing Details**\n",
    "\n",
    "1. **Initialize Parameters**\n",
    "   Randomly initialized in the range `[0, 2π]` to match typical rotation gate requirements for angle encoding.\n",
    "\n",
    "2. **Define Objective Function**\n",
    "   The cost function evaluates how well a given parameter set classifies training data.\n",
    "\n",
    "3. **Run Optimization**\n",
    "   Depending on the flag, either CMA-ES or COBYLA minimizes the cost over several iterations.\n",
    "\n",
    "#### **Output**\n",
    "\n",
    "* `optimized_params`: final optimized parameter vector\n",
    "* Logs the completion message and which optimizer was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d16c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_list = []\n",
    "\n",
    "# Callback function to save parameters and cost list at each iteration\n",
    "# This is useful for resuming optimization in case of interruptions or long queue times on real QPUs\n",
    "def callback(xk):\n",
    "    np.save(\"checkpoint_params.npy\", xk)\n",
    "    with open(\"cost_list_checkpoint.pkl\", \"wb\") as f:\n",
    "        pickle.dump(cost_list, f)\n",
    "\n",
    "# Due to long queue times and potential interruptions when running on real QPUs, we save the parameters and cost list at each iteration.\n",
    "if LOAD_FROM_CHECKPOINT and os.path.exists(\"checkpoint_params.npy\") and os.path.exists(\"cost_list_checkpoint.pkl\"):\n",
    "    init_params = np.load(\"checkpoint_params.npy\")\n",
    "    with open(\"cost_list_checkpoint.pkl\", \"rb\") as f:\n",
    "        cost_list = pickle.load(f)\n",
    "    print(\"Loaded parameters and cost list from checkpoint.\")\n",
    "    remaining_cobyla_iters = COBYLA_ITER_COUNT - len(cost_list)\n",
    "    remaining_cma_iters = CMA_ITER_COUNT - len(cost_list)\n",
    "    if USE_CMA:\n",
    "        print(f\"Remaining iterations for CMA-ES: {remaining_cma_iters}\")\n",
    "    else:\n",
    "        print(f\"Remaining iterations for COBYLA: {remaining_cobyla_iters}\")\n",
    "\n",
    "    print(\"Cost list:\", cost_list)\n",
    "    print(\"Initial parameters:\", init_params)\n",
    "else:\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "    init_params = 2 * np.pi * np.random.rand(QUBIT_COUNT * 2 * 2)\n",
    "    cost_list = []\n",
    "    print(\"Initialized new parameters and empty cost list.\")\n",
    "\n",
    "max_iters = COBYLA_ITER_COUNT if not USE_CMA else CMA_ITER_COUNT\n",
    "\n",
    "objective_function = lambda params: cost_function(X_train, Y_train, params, cost_list, sampler, pm, max_iters)\n",
    "\n",
    "param_count = len(init_params)\n",
    "\n",
    "if USE_CMA:\n",
    "    print(\"Starting optimization using CMA-ES...\\n\")\n",
    "    sigma0 = 0.1\n",
    "    result = cma.fmin2(\n",
    "        objective_function,\n",
    "        x0=init_params,\n",
    "        sigma0=sigma0,\n",
    "        options = {\n",
    "            'maxfevals': remaining_cma_iters,\n",
    "            'popsize': CMA_POPSIZE,\n",
    "            'verb_disp': 0                             \n",
    "        },\n",
    "        noise_handler=cma.NoiseHandler(param_count)\n",
    "    )\n",
    "    optimized_params = result[0]\n",
    "else:\n",
    "    print(\"Starting optimization using COBYLA...\\n\")\n",
    "    result = minimize(\n",
    "        objective_function,\n",
    "        x0=init_params,\n",
    "        method='COBYLA',\n",
    "        options={'maxiter': remaining_cobyla_iters},\n",
    "        callback=callback\n",
    "    )\n",
    "    optimized_params = result.x\n",
    "\n",
    "print(\"Optimization finished. Check next cell for detailed results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a565baca",
   "metadata": {},
   "source": [
    "After our optimization run is finished we will be able to see the following detailed results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5478ab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_CMA:\n",
    "    print(\"Optimization completed using CMA-ES.\")\n",
    "    print(\"Optimized Parameters:\", result[0])\n",
    "    print(\"Final Cost Value:\", result[1].best.f)\n",
    "else:\n",
    "    print(\"Optimization completed using COBYLA.\")\n",
    "    print(\"Optimized Parameters:\", result.x)\n",
    "    print(\"Final Cost Value:\", result.fun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b31998",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4fef2a",
   "metadata": {},
   "source": [
    "## **Result Visualization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dddb26",
   "metadata": {},
   "source": [
    "### **Cost Function Evolution**\n",
    "\n",
    "This section visualizes the evolution of the cost function during the training of a variational quantum classifier.\n",
    "\n",
    "We track how the cost value (Binary Cross-Entropy in our case) decreases as the optimizer adjusts the parameters over multiple steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dc5d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new figure for plotting\n",
    "fig = plt.figure()\n",
    "\n",
    "# Plot the cost value against optimization step index\n",
    "plt.plot(range(len(cost_list)), cost_list)\n",
    "\n",
    "# Label x and y axes\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Cost value')\n",
    "\n",
    "# Set the plot title based on the optimizer used\n",
    "if USE_CMA:\n",
    "    plt.title(\"CMA-ES BCE Cost value against steps\")\n",
    "else:\n",
    "    plt.title(\"COBYLA BCE Cost value against steps\")\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f52f8",
   "metadata": {},
   "source": [
    "### **Quantum Classifier Testing**\n",
    "\n",
    "This function evaluates the accuracy of a trained quantum classifier on test data using a provided backend and transpiler.\n",
    "\n",
    "#### **Processing Details**\n",
    "\n",
    "* Predicts class probabilities for each test sample using `classify()`.\n",
    "* Compares predicted label (`healthy` or `diseased`) with the true label.\n",
    "* Computes the proportion of correct predictions as the test accuracy.\n",
    "* Supports repeated evaluation to average out quantum noise or randomness.\n",
    "\n",
    "#### **Output**\n",
    "\n",
    "Prints individual and average test accuracy across multiple iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b65b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(X: list, Y: list, params: list, sampler: any, pm: any) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate the accuracy of a trained quantum classifier on a test dataset.\n",
    "\n",
    "    Args:\n",
    "        X (list): Test feature samples.\n",
    "        Y (list): Ground truth labels (0 = healthy, 1 = diseased).\n",
    "        params (list): Optimized quantum circuit parameters.\n",
    "        sampler: Quantum sampler backend to run the circuits. Either a simulator or a real quantum backend.\n",
    "        pm: Quantum processor manager or transpiler to prepare circuits.\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the classifier on the test data.\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    training_samples = X\n",
    "\n",
    "    # Get class probability predictions for each test sample\n",
    "    probs = classify(training_samples, params, sampler, pm)\n",
    "\n",
    "    # Compare predictions with ground truth\n",
    "    for i, prob in enumerate(probs):\n",
    "        predicted_label = 0 if prob.get(CLASS_LABELS[0], 0) >= prob.get(CLASS_LABELS[1], 0) else 1\n",
    "        true_label = Y[i]\n",
    "        if predicted_label == true_label:\n",
    "            correct += 1\n",
    "\n",
    "    accuracy = correct / len(Y)\n",
    "    print(f\"Test Accuracy - {accuracy:.4f} ({correct}/{len(Y)} correct predictions)\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4bed45",
   "metadata": {},
   "source": [
    "Finally, we can test our model to check how well it classifies unseen data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf0ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "\n",
    "print(f\"Running model testing over {TEST_ITER_COUNT} iterations...\\n\")\n",
    "\n",
    "# Run model multiple times and store accuracy\n",
    "for i in range(TEST_ITER_COUNT):\n",
    "    print(f\"Iteration {i + 1}/{TEST_ITER_COUNT}...\", end=\" \")\n",
    "    \n",
    "    if USE_CMA:\n",
    "        acc = test_model(X_test, Y_test, result[1].best.x, sampler, pm)\n",
    "    else:\n",
    "        acc = test_model(X_test, Y_test, result.x, sampler, pm)\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# Compute statistics\n",
    "mean_acc = np.mean(accuracies)\n",
    "std_acc = np.std(accuracies, ddof=1)\n",
    "conf_int = st.t.interval(0.95, len(accuracies) - 1, loc=mean_acc, scale=std_acc / np.sqrt(len(accuracies)))\n",
    "\n",
    "# Print results\n",
    "print(\"\\n================= Final Evaluation =================\")\n",
    "print(f\"Mean Accuracy:           {mean_acc:.4f}\")\n",
    "print(f\"Standard Deviation:      {std_acc:.4f}\")\n",
    "print(f\"95% Confidence Interval: [{conf_int[0]:.4f}, {conf_int[1]:.4f}]\")\n",
    "print(\"=========================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fe8142",
   "metadata": {},
   "source": [
    "To save our results to be able to compare to them later if we modify parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9eb2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "    \"qubit_count\": QUBIT_COUNT,\n",
    "    \"shot_count\": SHOT_COUNT,\n",
    "    \"class_labels\": CLASS_LABELS,\n",
    "    \"heart_data_path\": HEART_DATA_PATH,\n",
    "    \"test_size\": TEST_SIZE,\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"optimizer\": \"CMA-ES\" if USE_CMA else \"COBYLA\",\n",
    "    \"optimizer_iterations\": CMA_ITER_COUNT if USE_CMA else COBYLA_ITER_COUNT,\n",
    "    \"cma_popsize\": CMA_POPSIZE if USE_CMA else None,\n",
    "    \"use_real_backend\": USE_REAL_BACKEND,\n",
    "    \"backend\": backend.name,\n",
    "    \"region\": REGION,\n",
    "    \"test_iterations\": TEST_ITER_COUNT,\n",
    "    \"mean_accuracy\": round(mean_acc, 4),\n",
    "    \"std_deviation\": round(std_acc, 4),\n",
    "    \"confidence_interval\": [round(conf_int[0], 4), round(conf_int[1], 4)],\n",
    "    \"cost_list\": cost_list\n",
    "}\n",
    "\n",
    "# Output filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "filename = f\"evaluation_results_{timestamp}.json\"\n",
    "output_dir = \"results\"\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save as JSON\n",
    "with open(os.path.join(output_dir, filename), \"w\") as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(f\"\\n📁 Results saved to: {os.path.join(output_dir, filename)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53321a35",
   "metadata": {},
   "source": [
    "**Optional**: Compare to a different run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d314ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_comparison_run(current_optimizer, custom_name=None):\n",
    "    results_path = \"results\"\n",
    "    if custom_name:\n",
    "        # User-specified filename\n",
    "        file_path = os.path.join(results_path, f\"{custom_name}.json\")\n",
    "        if os.path.exists(file_path):\n",
    "            return json.load(open(file_path))\n",
    "        else:\n",
    "            print(f\"⚠️ File '{custom_name}.json' not found in 'results/'.\")\n",
    "            return None\n",
    "    else:\n",
    "        # Automatically find the latest result from the *other* optimizer\n",
    "        files = sorted(glob.glob(os.path.join(results_path, \"evaluation_results_*.json\")), reverse=True)\n",
    "        for f in files:\n",
    "            with open(f) as file:\n",
    "                data = json.load(file)\n",
    "                if data[\"optimizer\"] != current_optimizer:\n",
    "                    return data\n",
    "        print(\"No previous run found using the other optimizer.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f827aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_configurations(current, previous, keys_to_check):\n",
    "    diffs = []\n",
    "    for key in keys_to_check:\n",
    "        current_val = current.get(key, None)\n",
    "        previous_val = previous.get(key, None)\n",
    "        if current_val != previous_val:\n",
    "            diffs.append((key, previous_val, current_val))\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23498945",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPARE_TO = None  # Set this to the filename without .json if you want a specific one (e.g., \"evaluation_results_20250716_180000\")\n",
    "comparison = load_comparison_run(\"CMA-ES\" if USE_CMA else \"COBYLA\", COMPARE_TO)\n",
    "\n",
    "if comparison:\n",
    "    print(\"\\n================= Comparison with Previous Run =================\")\n",
    "    print(f\"Previous Run Timestamp:  {comparison['timestamp']}\")\n",
    "    print(f\"Optimizer Used:          {comparison['optimizer']}\")\n",
    "    print(f\"Mean Accuracy:           {comparison['mean_accuracy']:.4f}\")\n",
    "    print(f\"Standard Deviation:      {comparison['std_deviation']:.4f}\")\n",
    "    ci = comparison['confidence_interval']\n",
    "    print(f\"95% Confidence Interval: [{ci[0]:.4f}, {ci[1]:.4f}]\")\n",
    "\n",
    "    # Accuracy delta\n",
    "    delta = mean_acc - comparison['mean_accuracy']\n",
    "    better = \"↑ Better\" if delta > 0 else \"↓ Worse\" if delta < 0 else \"→ Same\"\n",
    "    print(f\"\\nAccuracy delta vs previous: {delta:.4f} ({better})\")\n",
    "\n",
    "    # Check for differing run parameters\n",
    "    print(\"\\nConfiguration Differences:\")\n",
    "    keys_to_check = [\n",
    "        \"qubit_count\", \"shot_count\", \"test_size\", \"random_state\",\n",
    "        \"optimizer\", \"optimizer_iterations\", \"cma_popsize\", \n",
    "        \"use_real_backend\", \"region\", \"test_iterations\", \"heart_data_path\"\n",
    "    ]\n",
    "    config_diffs = compare_configurations(results, comparison, keys_to_check)\n",
    "\n",
    "    if config_diffs:\n",
    "        for key, old, new in config_diffs:\n",
    "            print(f\" - {key}: previous = {old} | current = {new}\")\n",
    "    else:\n",
    "        print(\" - None (All matching)\")\n",
    "\n",
    "    print(\"===============================================================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
